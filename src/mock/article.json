{"title":"The Ironies of Automation","authors":["Lisanne Bainbridge"],"abstract":"<p>This paper discusses the ways in which automation of industrial processes may expand rather than eliminate problems with the human operator. Some comments will be made on methods of alleviating these problems within the 'classic' approach of leaving the operator with responsibility for abnormal conditions, and on the potential for continued use of the human operator for on-line decision-making within human-computer collaboration.</p>",
"content":"<p><strong><em>Irony</em></strong>: combination of circumstances, the result of which is the direct opposite of what might be expected.</p><p><strong><em>Paradox</em></strong>: seemingly absurd though perhaps really well-founded statement.</p><p>THE classic aim of automation is to replace human manual control, planning and problem solving by automatic devices and computers. However, as Bibby and colleagues (1975) point out: <span id=\"inline-0\" class=\"inlineNote\" data=\"0\">\"even highly automated systems, such as electric power networks, need human beings for supervision, adjustment, main.tenance, expansion and improvement. Therefore one can draw the paradoxical conclusion that automated systems still are man-machine systems, for which both technical and humanfactors are important.\"</span><span id=\"release-0\"></span> This paper suggests that the increased interest in human factors among engineers reflects the irony that the more advanced a control system is, so the more crucial may be the contribution of the human operator.</p><p><span id=\"inline-1\" class=\"inlineNote\" data=\"1\">\"This paper is particularly concerned with control in process industries, although examples will be drawn from flight-deck automation.</span><span id=\"release-1\"></span> In process plants the different modes of operation may be automated to different extents, for example normal operation and shut-down may be atomatic while start-up and abnormal conditions are manual. The problems of the use of automatic or manual control are a function of the predictability of process behaviour, whatever the mode of operation. The first two sections of this paper discuss automatic on-line control where a human operator is expected to take-over in abnormal conditions, the last section introduces some aspects of humancomputer collaboration in on-line control.</p> <h3><em>1. Introduction</em></h3><p>The important ironies of the classic approach to automation lie in the expectations of the system designers, and in the nature of the tasks left for the human operators to carry out.</p><p><span id=\"inline-2\" class=\"inlineNote\" data=\"2\">\"The designer's view of the human operator may be that the operator is unreliable and inefficient, so should be eliminated from the system.</span><span id=\"release-2\"></span> There are two ironies of this attitude. One is that designer errors can be a major source of operating problems. Unfortunately people who have collected data on this are reluctant to publish them, as the actual figures are difficult to interpret. (Some types of error may be reported more readily than others, and there may be disagreement about their origin.) The second irony is that the designer who tries to eliminate the operator still leaves the operator to do the tasks which the designer cannot think how to automate. It is this approach which causes the problems to be discussed here, as it means that the operator can be left with an arbitrary collection of tasks, and little thought may have been given to providing support for them.</p><p><em>1.1. Tasks after automation.</em> There are two general categories of task left for an operator in an automated system. He may be expected to monitor that the automatic system is operating correctly, and if it is not he may be expected to call a more experienced operator or to take-over himself. <span id=\"inline-3\" class=\"inlineNote\" data=\"3\">\"We will discuss the ironies of manual take-over first, as the points made also have implications for monitoring.</span><span id=\"release-3\"></span> To take over and stabilize the process requires manual control skills, to diagnose the fault as a basis for shut down or recovery requires cognitive skills.</p>",
"references":[{"cite":"Bainbridge, L (1975). The representation of working storage and its use in the organisation of behaviour. In W. T. Singleton and P. Spurgeon (Eds.), Measurement of Human Resources. Taylor and Francis, London, pp. 165 183.", "doi":""},
{"cite":" Bainbridge, L. (1981). Mathematical equations or processing routines? In J. Rasmussen and W. B. Rouse (Eds.), op. cir., pp. 259-286.", "doi":""},
{"cite":"Bibby, K. S., F. Margulies, J. E. Rijnsdorp and R. M. J. Withers (1975). Man's role in control systems. Proc. 6th IFAC Congress, Boston.","doi":""},
{"cite":"Chafin, R. L. (1981). A model for the control mode man-computer interface. Proc. 17th Ann. Conf on Manual Control, UCLA. JPL Publication 81-95, pp. 669 682.","doi":""},
{"cite":"Chu, Y. and W. B. Rouse (1979). Adaptive allocation of decision making responsibility between human and computer in multitask situations. IEEE Trans. Syst., Man & Cybern., SMC-9, 769.","doi":""},
{"cite":"Craik, F. M. 11979). Human memory. Ann. Rev. Psychol., 30, 63. Dellner, W. J. (1981 ). The user's role in automated fault detection and system recovery. In J. Rasmussen and W. B. Rouse (Eds.), op. cit., pp. 487--499.","doi":""},
{"cite":"Duncan, K. D. (1981). Training for fault diagnosis in industrial process plant. In J. Rasmussen and W. B. Rouse (Eds.), op. cir., pp. 553-573.","doi":""},
{"cite":"Duncan, K. D. and A. Shepherd (1975). A simulator and training technique for diagnosing plant failures from control panels. Ergonomics, 18, 627.","doi":""},
{"cite":"Edwards, E. (1981). Current research needs in manual control. Proc. 1st European Ann. Con]', on Human Decision Making and Manual Control, Delft University, pp. 228-232.","doi":""},
{"cite":"Edwards, E. and F. P. Lees (Eds.) (1974). The Human Operator in Process Control. Taylor and Francis, London.  Brief Paper 779","doi":""},
{"cite":"Ekkers, C. L., C. K. Pasmooij, A. A. F. Brouwers and A. J. Janusch (1979). Human control tasks: A comparative study in different man-machine systems. In J. E. Rijnsdorp (Ed.), Case Studies in Automation Related to Humanization of Work. Pergamon Press, Oxford, pp. 23-29.","doi":""},
{"cite":"Enstrom, K. O. and W. B. Rouse (1977). Real-time determination of how a human has allocated his attention between control and monitoring tasks. IEEE Trans. Syst., Man & Cybern., SMC-7, 153.","doi":""},
{"cite":"Ephrath, A. R. (1980). Verbal presentation. NATO Symposium on Human Detection and Diagnosis of System Failures, Roskilde, Denmark.","doi":""},
{"cite":"Ephrath, A. R. and L. R. Young (1981). Monitoring vs. man-inthe-loop detection of aircraft control failures. In J. Rasmussen and W. B. Rouse (Eds.), op. cir., pp. 143-154.","doi":""},
{"cite":"Gaodstein, L. P. (1981). Discriminative display support for process operators. In J. Rasmussen and W. B. Rouse (Ed.), op. cit., pp. 433-449.","doi":""},
{"cite":"Jervis, M. W. and R. H. Pope (1977). Trends in operator-process communication development. Central Electricity Generating Board, E/REP/054/77.", "doi":""},
{"cite":"Johannsen, G. and W. B. Rouse (1981). Problem solving behaviour of pilots in abnormal and emergency situations. Proc. 1st European Ann. Conf. on Human Decision Making and Manual Control, Delft University, pp. 142-150.", "doi":""},
{"cite":"Kreifeldt, J. G. and M. E. McCarthy (1981). Interruption as a test of the user-computer interface. Proc. 17th Ann. Conf. on Manual Control, UCLA. JPL Publication 81-95, pp. 655-667.","doi":""},
{"cite":"Mackworth, N. H. (1950). Researches on the measurement of human performance. Reprinted in H. W. Sinaiko (Ed.), Selected Papers on Human Factors in the Design and Use of Control Systems (1961). Dover Publications, New York, pp. 174-331.", "doi":""},
{"cite":"Marshall, E. C. and A. Shepherd (1981). A fault-finding training programme for continuous plant operators. In J. Rasmussen and W. B. Rouse (Eds.), op. cit., pp. 575-588.","doi":""},
{"cite":"Mobley, W. H., R. W. Griffeth, H. H. Hand and B. M. Meglino (1979). Review and conceptual analysis of the employee turnover process. Psychol. Bull., 86, 493.","doi":""},
{"cite":"Rasmussen, J. (1979). On the structure of knowledge--a morphology of mental models in a man-machine system context. Riso National Laboratory, Denmark, RISO-M-2192.","doi":""},
{"cite":"Rasmussen, J. and M. Lind (1981). Coping with complexity. Proc. 1st European Ann. Conf. on Human Decision Making and Manual Control, Delft University, pp. 70-91.","doi":""},
{"cite":"Rasmussen, J. and W. B. Rouse (Eds.) (1981). Human Detection and Diagnosis of System Failures. Plenum Press, New York.","doi":""},
{"cite":"Rouse, W. B. (1981). Human-computer interaction in the control of dynamic systems. Computing Surveys, 13, 71.","doi":""},
{"cite":"Ruffell-Smith, P. (1979). A simulator study of the interaction of pilot workload with errors, vigilance, and decisions, NASA TM-78482.","doi":""},
{"cite":"Sinaiko, H. W. (1972). Human intervention and full automation in control systems. Appl. Ergonomics, 3, 3.","doi":""},
{"cite":"Thompson, D. A. (1981). Commercial air crew detection of system failures: state of the art and future trends. In J. Rasmussen and W. B. Rouse (Eds.), op. cit., pp. 37-48,","doi":""},
{"cite":"Wiener, E. L. and R. E. Curry (1980), Flight-deck automation: promises and problems. Ergonomics, 23, 995.", "doi":""}],
"notes":[{"text":"Lorem ipsume mwhahaha","id":0},{"text":"more text","id":1}, {"text":"some longer text w-pjefpeogj;dlgjm;d wonhr fxoeihg orgnlrw wfdenorw igjerlg jlnfbem ,","id":2},{"text":"I can't fight this feeling anymore. I've forgotten what I started fighting for. something something something... cause I can't fight this feeling anymore!!!","id":3}]
}